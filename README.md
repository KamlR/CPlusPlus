# Контрольное домашнее задание по прикладным методам математической статистики
## Работа выполнена Мавлетовой Кариной Радиковной (БПИ216) и Краснослободцевым Кирилом Дмитриевичем (БПИ218)
## Вариант 2:

### Встпуление:
В нашей работе мы проанализировали данные о бывших заключённых, опираясь на задания варианта номер 2. В качестве инструмента для анализа данных был использован язык Python.
Были использованы следующие библиотеки:
```
numpy
pandas
sklearn.linear_model
statsmodels.api
sklearn.metrics
scipy
matplotlib.pyplot
```
Для выполнения задания мы выбрали следующие переменные:
```
recid – объясняемая переменная
age, black, married, drugs, rules - регрессоры
```
Как мы подготовили данные для анализа:
- Считали датасет для 2 варианта
- Удалили столбцы alcohol, educ, felon
- Создали выборку, убрав последние 50 наблюдений, так как для них не нужно значение recid по условию. Чуть позже для пункта 8 мы их вернули.

Получили следующую таблицу:

![photo_2023-06-02_15-32-43](https://github.com/KamlR/CPlusPlus/assets/115434090/75b594ee-82c6-4183-ae6c-042edace90b5)
### Вопрос 6: 
Для каждого пункта ниже мы выделили отдельно зависимые и независимые переменные и, используя функции Python, получили свободный член и коэффициенты для каждой из 3 моделей.
#### :white_check_mark:Оцените линейную модель, связывающую вероятность повторного преступления с остальными признаками:
![photo_2023-06-02_15-52-27](https://github.com/KamlR/CPlusPlus/assets/115434090/1e79b01f-3d76-4a68-8e4a-81ec6c8a7592)

#### :white_check_mark:Оцените логит модель, связывающую вероятность повторного преступления с остальными признаками:
![photo_2023-06-02_15-53-27](https://github.com/KamlR/CPlusPlus/assets/115434090/f7a12a7e-c9e5-4725-9c04-dd6d762b7551)

#### :white_check_mark:Оцените пробит модель, связывающую вероятность повторного преступления с остальными признаками:
![photo_2023-06-02_15-53-55](https://github.com/KamlR/CPlusPlus/assets/115434090/71f9c76d-5ceb-476a-9a58-254146b50f0d)

#### Вывод:
В ходе выполнения 6 задания были получены оценочные коэффициенты для 3 моделей регрессии.

### Вопрос 7:
#### :white_check_mark:Дайте словесное описание полученных результатов на примере probit-модели. Какие из переменных получились значимыми? 
Ниже отдельно опишем, как каждый коэффициент повлиял на значимость переменной.
Для удобства имена коэффициентов ниже соответствуют названиям переменных.
- black = 0.325683 делает переменную значимой и показывает, что люди с тёмным цветом кожи с большой вероятностью пойдут на повторное преступление.
- drugs = 0.199177 - также делает переменную значимой  и показывает, что люди, имеющие проблемы с наркотиками, способны совершить повторное преступление. Однако, этот фактор менее значим, чем пред.
- rules = 0.069656 очень слабо влияет на вероятность того, что человек пойдёт на повторное преступление.
- age = -0.000482, т.е. переменная также является значимой и показывает, что чем старше человек, тем с меньшей вероятностью он совершает повторное преступление.
- married = -0.174069 делает переменную значимой и уменьшает вероятность совершения повторного преступления.

#### :white_check_mark:Выпишите оцененную ковариационную матрицу оценок коэффициентов
<img width="605" alt="image" src="https://github.com/KamlR/CPlusPlus/assets/115434090/0d3bb793-d715-4104-86db-8da54999baaa">

#### Вывод:
Таким образом, используя данные из 6 пункта, мы объяснили, как каждый коэффициент влияет на значимость соотв. переменной. Выяснилось, что каждая переменная, анализируемая нами, оказалось значимой.
Также мы получили оцененную ковариационную матрицу оценок коэффициентов.

### Вопрос 8:
В данном пункте цель следующая: по уже известным коэффициентам для каждой модели расчитать вероятность совершения повторного пресупления и сравнить полученные результаты с имеющмися в таблице.
Ниже будут представлены таблицы с полученными вероятностями.
#### :white_check_mark: Оцените вероятность повторного преступления для всех наблюдений, включая 50 последних (где неизвестно значение recid) для линейной модели.
![photo_2023-06-02_16-39-02](https://github.com/KamlR/CPlusPlus/assets/115434090/9762d37a-1ef0-465b-a36c-319d69d0dc27)

#### :white_check_mark: Оцените вероятность повторного преступления для всех наблюдений, включая 50 последних (где неизвестно значение recid) для логит модели.
![photo_2023-06-02_16-42-01](https://github.com/KamlR/CPlusPlus/assets/115434090/a8c298db-b8aa-42a6-8add-d7fe1023152b)

#### :white_check_mark: Оцените вероятность повторного преступления для всех наблюдений, включая 50 последних (где неизвестно значение recid) для пробит модели.
![photo_2023-06-02_16-43-33](https://github.com/KamlR/CPlusPlus/assets/115434090/07e9e648-5fbf-467e-a61a-b718b37d9102)

#### :white_check_mark:Есть ли заметные различия между прогнозируемыми вероятностями?
Ниже представлена таблица, в которой указаны различия между прогнозируемыми вероятностями соотв. моделей.
Считали мы их след. образом:
- брали две модели
- получали квадрат разницы между соотв. значениями
- складывали значения из прошлого пункта
- полученную сумму делили на общее количетство наблюдений

![photo_2023-06-02_16-51-17](https://github.com/KamlR/CPlusPlus/assets/115434090/ea42d4aa-7bcf-409e-8477-3f6cf1a2b315)

#### :white_check_mark:В каких наблюдениях возникают наибольшие расхождения? 
Смотря на таблицу выше, можно с уверенностью сказать, что наибольшие расхождения возникают между 1 и 2 моделями.

#### :white_check_mark: Кому из ещё не совершивших рецидива бывших заключенных требуется уделить особое внимание?
Это мы выяснили следующим образом:
- Используя коэффициенты, посчитанные в 6 пункте, оценили вероятность совершения повторного преступления для последних 50 заключённых.
Ниже представлена таблица номеров заключённых, на которых следует обратить особое внимание. Т.е они в теории с большей вероятностью относительно других (берём 50 последних) могут пойти на повторное преступление.
![photo_2023-06-02_17-03-51](https://github.com/KamlR/CPlusPlus/assets/115434090/22cbd735-e842-4e0c-8e80-1b978567afc3)

#### Вывод:
В данном пункте, используя ранее посчитанные коэффициенты - мы рассчитали для каждой модели вероятности совершения повторного преступления. Далее мы сравнили полученные результаты и выяснили, что наибольшие расхождения в значениях вероятснотей имеют 1 и 2 модели.
Также мы выяснили, что на 9/50 заключённых с конца нужно обратить особое внимание, так как по полученным вероятностям они могут пойти на повторное преступление.

### Вопрос 9:
Значимость модели позволяет нам понять, насколько её параметры верно описывают зависимую переменную. Обратим внимание на то, что в нашей текущей модели нет переменных, которые отвечают за алкоголь, образование и тяжесть ранее совершённого преступления.
Так вот, нам предстоит понять, насколько хорошо модель может предсказывать результат без этих переменных.
#### :white_check_mark: На примере probit модели проверьте значимость модели в целом тестом отношения правдоподобия:
- Мы взяли коэффициенты UR-модели(где есть все переменные):

![photo_2023-06-02_17-25-24](https://github.com/KamlR/CPlusPlus/assets/115434090/dcdd51d2-e159-4175-a4ef-3a4157be6b34)
- Также взяли коэффициенты R-модели:

![photo_2023-06-02_17-26-34](https://github.com/KamlR/CPlusPlus/assets/115434090/715e230d-a74d-416b-bc02-380c1938c980)
- Далее применяя функции Python, провели тест отношения правдободобия:

![photo_2023-06-02_17-31-18](https://github.com/KamlR/CPlusPlus/assets/115434090/bae3a7de-316e-4b1a-a854-7580c8b4ad67)

Какой можно сделать вывод на основе полученного значения?
Знаем, что значение, полученное тестом отношения правдободобия, имеет распределние хи квадрат, в нашем случае с 3 степенями свободы. Возьмём за уровень значимости распостранённое значение = 0.05. Тогда определим границу критической области. chi2inv(1-0.05, 3) = chi2inv(0.95, 3) = 7.8. Т.е LRT наблюдаемое превышает данное значенине, а значит мы можем сделать вывод о том, что более сложная модель (где нет ограничений) лучше объясняет данные. 

#### :white_check_mark: Рассчитайте p-значение:
![photo_2023-06-05_19-44-20](https://github.com/KamlR/CPlusPlus/assets/115434090/7cb33e2d-d147-48a5-8e63-2a337505f680)

Получили крайне маленькое значение. Чем меньше p-значение, тем менее вероятно, что нулевая гипотеза соответствует реальности. А нулевая гипотеза - это та, в которой коэффциенты при некоторых переменных зануляются. Получается, что выводы в двух пунктах совпали.

#### Вывод:
При помощи теста отношения правдободобия на примере probit модели проверили её значимость. Т.е нам нужно быдо понять, насколько хорошо модель, в которой занулены коэффициенты при переменных, отвечающих за алкоголь, образование и тяжесть ранее совершённого преступления, объясняет данные. В итоге поняли, что более сложная модель, в которой ничего не зануляется, данные объясняет лучше. А это значит, что для получения более корректного результата нужно использовать все переменные.

### Вопрос 10:
#### :white_check_mark: График зависимости чувствительности и специфичности от c:
![photo_2023-06-05_20-22-34](https://github.com/KamlR/CPlusPlus/assets/115434090/bb7eb924-2be9-42b9-999d-c87244582b11)

Получился вполне ожидаемый график. Чем ниже пороговое значение, тем выше чувствительность. А чем выше пороговое значение, тем выше специфичность. Если же c = ~ 0.4 , то сильных расхождений нет.
На самом деле, при c = ~ 0.4  доля верных предсказаний, как для 0, так и для 1 около 55% по графику, не супер большой.
Для интереса, мы решили посмотреть, а какой же будет результат, если мы добавим ранее убранные переменные.
Получился следующий график:

![photo_2023-06-05_22-10-12](https://github.com/KamlR/CPlusPlus/assets/115434090/c01e0273-6df2-49a3-8491-0852a3153270)

Не то чтобы результат при с = ~ 0.4 сильно изменился, но всё же повысился до 60%. Это уже который раз доказывает, что UR-модель лучше объясняет данные в нашем случае.

#### :white_check_mark: Требуется, чтобы прогнозная модель имела чувствительность не ниже 80%. Каким должен быть порог c? Какой специфичности можно добиться в этом случае?
Ниже представлена таблица, где указано чему должно быть равно с и чему равна специфичность, когда чувствительность не ниже 80%.

![photo_2023-06-05_22-12-27](https://github.com/KamlR/CPlusPlus/assets/115434090/ea151300-ed76-40ff-b829-3bcd21f35b9e)

Выходит, что для получении 80% совпадающих результатов для 1, с должна быть в диапазоне [0.1; 0.3]

#### Вывод:
В logit модели 0 и 1 зависят от порога c. Также знаем, что чувствительность - доля верных 1, специфичность - доля верных нулей. Т.е предсказания совпадают с реальными результатами. Был построен график зависимости чувствительности и специфичности от с. График показал, что при маленьком значении c чувствительность крайне высока, при высоком значении c специфичность крайне высока. А вот при с =  ~ 0.4 доли верных 0 и 1 совпадают. Также выяснили, что при использовании всех переменных в logit модели, доли верных предсказаний при c = ~ 0.4 чуть выше, чем в R модели. 
